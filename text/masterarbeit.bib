
@article{kalos_monte_2008,
	title = {Monte Carlo Methods - Second Revised and Enlarged Edition},
	pages = {217},
	journaltitle = {Wiley Blackwell},
	author = {Kalos, Malvin and Whitlock, Paula},
	date = {2008},
	langid = {english},
	file = {Monte Carlo Methods - Second Revised and Enlarged .pdf:/Users/Dodo/Zotero/storage/EDXSC24N/Monte Carlo Methods - Second Revised and Enlarged .pdf:application/pdf}
}

@article{jacka_optimal_1991,
	title = {Optimal Stopping and the American Put},
	volume = {1},
	issn = {0960-1627, 1467-9965},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-9965.1991.tb00007.x},
	doi = {10.1111/j.1467-9965.1991.tb00007.x},
	pages = {1--14},
	number = {2},
	journaltitle = {Mathematical Finance},
	author = {Jacka, S. D.},
	urldate = {2021-09-20},
	date = {1991-04},
	langid = {english},
	file = {Jacka - 1991 - Optimal Stopping and the American Put.pdf:/Users/Dodo/Zotero/storage/8NB2VJNT/Jacka - 1991 - Optimal Stopping and the American Put.pdf:application/pdf}
}

@article{bayer_optimal_2020,
	title = {Optimal Stopping with Signatures},
	pages = {38},
	author = {Bayer, C and Hager, P and Riedel, S and Schoenmakers, J},
	date = {2020},
	langid = {english},
	file = {Bayer et al. - OPTIMAL STOPPING WITH SIGNATURES.pdf:/Users/Dodo/Zotero/storage/AQXBYA8Q/Bayer et al. - OPTIMAL STOPPING WITH SIGNATURES.pdf:application/pdf}
}

@article{kalsi_optimal_2020,
	title = {Optimal Execution with Rough Path Signatures},
	volume = {11},
	issn = {1945-497X},
	url = {https://epubs.siam.org/doi/10.1137/19M1259778},
	doi = {10.1137/19M1259778},
	abstract = {We present a method for obtaining approximate solutions to the problem of optimal execution, based on a signature method. The framework is general, only requiring that the price process is a geometric rough path and the price impact function is a continuous function of the trading speed. Following an approximation of the optimization problem, we calculate an optimal solution for the trading speed in the space of linear functions on a truncation of the signature of the price process. We provide strong numerical evidence illustrating the accuracy and flexibility of the approach. Our numerical investigation both examines cases where exact solutions are known, demonstrating that the method accurately approximates these solutions, and models where closed-form solutions of the optimal trading speed are not known. In the latter case, we obtain favorable comparisons with standard execution strategies.},
	pages = {470--493},
	number = {2},
	journaltitle = {{SIAM} J. Finan. Math.},
	author = {Kalsi, Jasdeep and Lyons, Terry and Arribas, Imanol Perez},
	urldate = {2021-09-20},
	date = {2020-01},
	langid = {english},
	file = {Kalsi et al. - 2020 - Optimal Execution with Rough Path Signatures.pdf:/Users/Dodo/Zotero/storage/ZFWGEWUC/Kalsi et al. - 2020 - Optimal Execution with Rough Path Signatures.pdf:application/pdf}
}

@article{bonate_brief_2001,
	title = {A Brief Introduction to Monte Carlo Simulation:},
	volume = {40},
	issn = {0312-5963},
	url = {http://link.springer.com/10.2165/00003088-200140010-00002},
	doi = {10.2165/00003088-200140010-00002},
	shorttitle = {A Brief Introduction to Monte Carlo Simulation},
	pages = {15--22},
	number = {1},
	journaltitle = {Clinical Pharmacokinetics},
	author = {Bonate, Peter L.},
	urldate = {2021-09-20},
	date = {2001},
	langid = {english},
	file = {Bonate - 2001 - A Brief Introduction to Monte Carlo Simulation.pdf:/Users/Dodo/Zotero/storage/55HN8FTB/Bonate - 2001 - A Brief Introduction to Monte Carlo Simulation.pdf:application/pdf}
}

@article{kingma_adam_2017,
	title = {Adam: A Method for Stochastic Optimization},
	url = {http://arxiv.org/abs/1412.6980},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for ﬁrst-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efﬁcient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss {AdaMax}, a variant of Adam based on the inﬁnity norm.},
	journaltitle = {{arXiv}:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	urldate = {2021-09-20},
	date = {2017-01-29},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1412.6980},
	keywords = {Computer Science - Machine Learning},
	file = {Kingma und Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:/Users/Dodo/Zotero/storage/3LZZ4PWP/Kingma und Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf}
}

@article{shevchenko_fractional_2014,
	title = {Fractional Brownian motion in a nutshell},
	url = {http://arxiv.org/abs/1406.1956},
	abstract = {This is an extended version of the lecture notes to a mini-course devoted to fractional Brownian motion and delivered to the participants of 7th Jagna International Workshop.},
	journaltitle = {{arXiv}:1406.1956 [math]},
	author = {Shevchenko, Georgiy},
	urldate = {2021-09-20},
	date = {2014-06-08},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1406.1956},
	keywords = {Mathematics - Probability},
	file = {Shevchenko - 2014 - Fractional Brownian motion in a nutshell.pdf:/Users/Dodo/Zotero/storage/SFVYM5MX/Shevchenko - 2014 - Fractional Brownian motion in a nutshell.pdf:application/pdf}
}

@article{shapiro_stochastic_2000,
	title = {Stochastic Programming by Monte Carlo Simulation Methods},
	abstract = {We consider in this paper stochastic programming problems which can be formulated as an optimization problem of an expected value function subject to deterministic constraints. We discuss a Monte Carlo simulation approach based on sample average approximations to a numerical solution of such problems. In particular, we give a survey of a statistical inference of the sample average estimators of the optimal value and optimal solutions of the true problem. We also discuss stopping rules and a validation analysis for such sample average approximation optimization procedures and give some illustration examples.},
	pages = {30},
	author = {Shapiro, Alexander},
	date = {2000},
	langid = {english},
	file = {Shapiro - Stochastic Programming by Monte Carlo Simulation M.pdf:/Users/Dodo/Zotero/storage/E7IQE59Q/Shapiro - Stochastic Programming by Monte Carlo Simulation M.pdf:application/pdf}
}

@article{wang_reltanh_2019,
	title = {{ReLTanh}: An activation function with vanishing gradient resistance for {SAE}-based {DNNs} and its application to rotating machinery fault diagnosis},
	volume = {363},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231219309464},
	doi = {10.1016/j.neucom.2019.07.017},
	shorttitle = {{ReLTanh}},
	pages = {88--98},
	journaltitle = {Neurocomputing},
	author = {Wang, Xin and Qin, Yi and Wang, Yi and Xiang, Sheng and Chen, Haizhou},
	urldate = {2021-09-20},
	date = {2019-10},
	langid = {english},
	file = {Wang et al. - 2019 - ReLTanh An activation function with vanishing gra.pdf:/Users/Dodo/Zotero/storage/CG5NZFDW/Wang et al. - 2019 - ReLTanh An activation function with vanishing gra.pdf:application/pdf}
}

@article{becker_deep_2019,
	title = {Deep Optimal Stopping},
	volume = {20},
	url = {http://jmlr.org/papers/v20/18-232.html},
	shorttitle = {{DeepOptimalStoping}},
	abstract = {In this paper we develop a deep learning method for optimal stopping problems which directly learns the optimal stopping rule from Monte Carlo samples. As such, it is broadly applicable in situations where the underlying randomness can efficiently be simulated. We test the approach on three problems: the pricing of a Bermudan max-call option, the pricing of a callable multi barrier reverse convertible and the problem of optimally stopping a fractional Brownian motion. In all three cases it produces very accurate results in high- dimensional situations with short computing times.},
	journaltitle = {Journal of Machine Learning Research},
	author = {Becker, Sebastian and Cheridito, Patrick and Jentzen, Arnulf},
	date = {2019},
	file = {18-232.pdf:/Users/Dodo/Zotero/storage/IDHSZF6D/18-232.pdf:application/pdf}
}

@book{friz_course_2014,
	title = {A Course on Rough Paths},
	author = {Friz, Peter and Hairer, Martin},
	date = {2014-06},
	file = {RoughPaths.pdf:/Users/Dodo/Zotero/storage/ZYL8KD5J/RoughPaths.pdf:application/pdf}
}

@book{klenke_wahrscheinlichkeites-theorie_2006,
	location = {Berlin},
	title = {Wahrscheinlichkeites-theorie},
	isbn = {9786610626755 9783540255451 9783540334149},
	url = {http://www.myilibrary.com?id=62675},
	pagetotal = {1},
	publisher = {Springer},
	author = {Klenke, Achim},
	urldate = {2021-09-20},
	date = {2006},
	langid = {german},
	note = {Medium: electronic resource},
	keywords = {Probabilities},
	file = {Klenke - 2006 - Wahrscheinlichkeites-theorie.pdf:/Users/Dodo/Zotero/storage/DH2A6HCE/Klenke - 2006 - Wahrscheinlichkeites-theorie.pdf:application/pdf}
}

@article{aliprantis_infinite_2006,
	title = {Infinite Dimensional Analysis},
	number = {3},
	journaltitle = {Springer},
	author = {Aliprantis, Charalambos and Border, Kim C.},
	date = {2006},
	file = {2006_Chapter_OddsAndEnds.pdf:/Users/Dodo/Zotero/storage/IHFCIJYD/2006_Chapter_OddsAndEnds.pdf:application/pdf}
}

@article{friz_multidimensional_2009,
	title = {Multidimensional Stochastic Processes as Rough Paths: Theory and Applications},
	pages = {672},
	author = {Friz, Peter K and Victoir, Nicolas B},
	date = {2009},
	langid = {english},
	file = {Friz und Victoir - Multidimensional Stochastic Processes as Rough Pat.pdf:/Users/Dodo/Zotero/storage/Y7QJE5ZA/Friz und Victoir - Multidimensional Stochastic Processes as Rough Pat.pdf:application/pdf}
}

@article{diehl_stochastic_1991,
	title = {Stochastic Partial Differential Equations: a Rough Path view},
	abstract = {We discuss regular and weak solutions to rough partial diﬀerential equations ({RPDEs}), thereby providing a (rough path-)wise view on important classes of {SPDEs}. In contrast to many previous works on {RPDEs}, our deﬁnition gives honest meaning to {RPDEs} as integral equation, based on which we are able to obtain existence, uniqueness and stability results. The case of weak “rough" forward equations, may be seen as robustiﬁcation of the (measure-valued) Zakai equation in the rough path sense. Feynman-Kac representation for {RPDEs}, in formal analogy to similar classical results in {SPDE} theory, play an important role.},
	pages = {28},
	author = {Diehl, Joscha and Friz, Peter K and Stannat, Wilhelm},
	date = {1991},
	langid = {english},
	file = {Diehl et al. - STOCHASTIC PARTIAL DIFFERENTIAL EQUATIONS A ROUGH.pdf:/Users/Dodo/Zotero/storage/QFMRJYB5/Diehl et al. - STOCHASTIC PARTIAL DIFFERENTIAL EQUATIONS A ROUGH.pdf:application/pdf}
}

@article{dupire_functional_2009,
	title = {Functional Itô Calculus},
	journaltitle = {Bloomberg L.P.},
	author = {Dupire, Bruno},
	date = {2009-07-17},
	file = {functional-it-calculus.pdf:/Users/Dodo/Zotero/storage/3Z6XG98J/functional-it-calculus.pdf:application/pdf}
}

@article{cont_functional_2010,
	title = {A functional extension of the Ito formula},
	volume = {348},
	issn = {1631073X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1631073X09003951},
	doi = {10.1016/j.crma.2009.11.013},
	abstract = {We develop a non-anticipative pathwise calculus for functionals of a Brownian semimartingale and its quadratic variation. A functional Ito formula is obtained for locally Lipschitz functionals of a Brownian semimartingale and its quadratic variation. As a result we obtain a constructive martingale representation theorem for Brownian martingales verifying a regularity property.},
	pages = {57--61},
	number = {1},
	journaltitle = {Comptes Rendus Mathematique},
	author = {Cont, Rama and Fournie, David},
	urldate = {2021-09-20},
	date = {2010},
	langid = {english},
	file = {Cont und Fournie - 2010 - A functional extension of the Ito formula.pdf:/Users/Dodo/Zotero/storage/US5LGES2/Cont und Fournie - 2010 - A functional extension of the Ito formula.pdf:application/pdf}
}

@article{wisniewski_structure_1992,
	title = {The Structure of Measurable Mapping on Metric Spaces},
	abstract = {The purpose of this paper is to investigate the conditions under which every measurable mapping on a metric space X with the measure p is a limit of a sequence of continuous mappings, with respect to the convergence /¿-almost everywhere.},
	pages = {4},
	author = {Wisniewski, Andrzej},
	date = {1992},
	langid = {english},
	file = {Wisniewski - THE STRUCTUREOF MEASURABLEMAPPINGS ON METRIC SPACE.pdf:/Users/Dodo/Zotero/storage/FD326PK6/Wisniewski - THE STRUCTUREOF MEASURABLEMAPPINGS ON METRIC SPACE.pdf:application/pdf}
}

@article{longstaff_valuing_2001,
	title = {Valuing American Options by Simulation: A Simple Least-Squares Approach},
	volume = {14},
	issn = {0893-9454, 1465-7368},
	url = {https://academic.oup.com/rfs/article-lookup/doi/10.1093/rfs/14.1.113},
	doi = {10.1093/rfs/14.1.113},
	shorttitle = {Valuing American Options by Simulation},
	pages = {113--147},
	number = {1},
	journaltitle = {Rev. Financ. Stud.},
	author = {Longstaff, Francis A. and Schwartz, Eduardo S.},
	urldate = {2021-09-20},
	date = {2001-01},
	langid = {english},
	file = {Longstaff und Schwartz - 2001 - Valuing American Options by Simulation A Simple L.pdf:/Users/Dodo/Zotero/storage/FAVX6VLI/Longstaff und Schwartz - 2001 - Valuing American Options by Simulation A Simple L.pdf:application/pdf}
}

@article{rogers_monte_2002,
	title = {Monte Carlo Valuation of American Options},
	abstract = {This paper introduces a dual way to price American options, based on simulating the paths of the option payoﬀ, and of a judiciously chosen Lagrangian martingale. Taking the pathwise maximum of the payoﬀ less the martingale provides an upper bound for the price of the option, and this bound is sharp for the optimal choice of Lagrangian martingale. As a ﬁrst exploration of this method, four examples are investigated numerically; the accuracy achieved with even very simple choices of Lagrangian martingale is surprising. The method also leads naturally to candidate hedging policies for the option, and estimates of the risk involved in using them.},
	pages = {16},
	author = {Rogers, L C G},
	date = {2002},
	langid = {english},
	file = {Rogers - MONTE CARLO VALUATION OF AMERICAN OPTIONS.pdf:/Users/Dodo/Zotero/storage/EMH6S9BU/Rogers - MONTE CARLO VALUATION OF AMERICAN OPTIONS.pdf:application/pdf}
}

@article{barola_monte_2013,
	title = {Monte Carlo Methods for American Option Pricing},
	pages = {153},
	author = {Barola, Alberto},
	date = {2013},
	langid = {english},
	file = {Barola - Monte Carlo Methods for American Option Pricing.pdf:/Users/Dodo/Zotero/storage/H2LSIQE4/Barola - Monte Carlo Methods for American Option Pricing.pdf:application/pdf}
}

@article{leshno_multilayer_1993,
	title = {Multilayer feedforward networks with a nonpolynomial activation function can approximate any function},
	volume = {6},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608005801315},
	doi = {10.1016/S0893-6080(05)80131-5},
	abstract = {Several researchers characterized the activation fimction under which multilayer feedforward networks can act as universal approximators. We show that most of all the characterizations that were reported thus far in the literature are special cases of the following general result: A standard multilayer feedforward network with a locally bounded piecewise continuous activation fimction can approximate an3, continuous function to any degree of accuracy if and only if the network's activation function is not a polynomial. We also emphasize the important role o f the threshold, asserting that without it the last theorem does not hold.},
	pages = {861--867},
	number = {6},
	journaltitle = {Neural Networks},
	author = {Leshno, Moshe and Lin, Vladimir Ya. and Pinkus, Allan and Schocken, Shimon},
	urldate = {2021-09-20},
	date = {1993-01},
	langid = {english},
	file = {Leshno et al. - 1993 - Multilayer feedforward networks with a nonpolynomi.pdf:/Users/Dodo/Zotero/storage/2596DLY3/Leshno et al. - 1993 - Multilayer feedforward networks with a nonpolynomi.pdf:application/pdf}
}

@article{duchi_adaptive_2011,
	title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
	abstract = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to ﬁnd needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which signiﬁcantly simpliﬁes setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efﬁcient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.},
	pages = {39},
	author = {Duchi, John and Hazan, Elad and Singer, Yoram},
	date = {2011},
	langid = {english},
	file = {Duchi et al. - Adaptive Subgradient Methods for Online Learning a.pdf:/Users/Dodo/Zotero/storage/J9JBTKLF/Duchi et al. - Adaptive Subgradient Methods for Online Learning a.pdf:application/pdf}
}

@article{zinkevich_online_2003,
	title = {Online Convex Programming and Generalized Infinitesimal Gradient Ascent},
	abstract = {Convex programming involves a convex set F ⊆ Rn and a convex cost function c : F → R. The goal of convex programming is to ﬁnd a point in F which minimizes c. In online convex programming, the convex set is known in advance, but in each step of some repeated optimization problem, one must select a point in F before seeing the cost function for that step. This can be used to model factory production, farm production, and many other industrial optimization problems where one is unaware of the value of the items produced until they have already been constructed. We introduce an algorithm for this domain. We also apply this algorithm to repeated games, and show that it is really a generalization of inﬁnitesimal gradient ascent, and the results here imply that generalized inﬁnitesimal gradient ascent ({GIGA}) is universally consistent.},
	pages = {8},
	author = {Zinkevich, Martin},
	date = {2003},
	langid = {english},
	file = {Zinkevich - Online Convex Programming and Generalized Infinite.pdf:/Users/Dodo/Zotero/storage/4HMLFXMD/Zinkevich - Online Convex Programming and Generalized Infinite.pdf:application/pdf}
}

@article{allan_model-free_2019,
	title = {Model-Free Portfolio Theory: A Rough Path Approach},
	abstract = {Based on a rough path foundation, we develop a model-free approach to stochastic portfolio theory ({SPT}). Our approach allows to handle signiﬁcantly more general portfolios compared to previous model-free approaches based on Fo¨llmer integration. Without the assumption of any underlying probabilistic model, we prove pathwise Master formulae analogous to those of classical {SPT}, describing the growth of wealth processes associated to functionally generated portfolios relative to the market portfolio. We show that the appropriately scaled asymptotic growth rate of a far reaching generalization of Cover’s universal portfolio based on controlled paths coincides with that of the best retrospectively chosen portfolio within this class. We provide several novel results concerning rough integration, and highlight the advantages of the rough path approach by considering (non-functionally generated) log-optimal portfolios in an ergodic Itoˆ diﬀusion setting.},
	pages = {41},
	author = {Allan, Andrew L and Cuchiero, Christa and Liu, Chong and Mel, David J Pro},
	date = {2019},
	langid = {english},
	file = {Allan et al. - MODEL-FREE PORTFOLIO THEORY A ROUGH PATH APPROACH.pdf:/Users/Dodo/Zotero/storage/F3Y26N69/Allan et al. - MODEL-FREE PORTFOLIO THEORY A ROUGH PATH APPROACH.pdf:application/pdf}
}

@book{lothaire_combinatorics_1983,
	location = {Reading, Mass},
	title = {Combinatorics on words},
	isbn = {978-0-201-13516-9},
	series = {Encyclopedia of mathematics and its applications ; Section, Algebra},
	pagetotal = {238},
	number = {v. 17},
	publisher = {Addison-Wesley, Advanced Book Program, World Science Division},
	author = {Lothaire, M.},
	date = {1983},
	langid = {english},
	keywords = {Combinatorial analysis, Word problems (Mathematics)},
	file = {Lothaire - 1983 - Combinatorics on words.pdf:/Users/Dodo/Zotero/storage/6PS7GTTC/Lothaire - 1983 - Combinatorics on words.pdf:application/pdf}
}

@article{lyons_extension_2007,
	title = {An extension theorem to rough paths},
	volume = {24},
	issn = {02941449},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0294144906001119},
	doi = {10.1016/j.anihpc.2006.07.004},
	abstract = {We show that any continuous path of ﬁnite p-variation can be lifted to a geometric q-rough path, where q {\textgreater} p. © 2006 Elsevier Masson {SAS}. All rights reserved. Résumé Nous montrons que tout chemin continu de p-variation ﬁnie peut être relevé en un « geometric q-rough path », pour q {\textgreater} p. © 2006 Elsevier Masson {SAS}. All rights reserved.},
	pages = {835--847},
	number = {5},
	journaltitle = {Annales de l'Institut Henri Poincaré C, Analyse non linéaire},
	author = {Lyons, Terry and Victoir, Nicolas},
	urldate = {2021-09-27},
	date = {2007-09},
	langid = {english},
	file = {Lyons und Victoir - 2007 - An extension theorem to rough paths.pdf:/Users/Dodo/Zotero/storage/JHTCBHLT/Lyons und Victoir - 2007 - An extension theorem to rough paths.pdf:application/pdf}
}

@book{lyons_differential_2007,
	location = {Berlin, Heidelberg},
	title = {Differential Equations Driven by Rough Paths},
	volume = {1908},
	isbn = {978-3-540-71284-8 978-3-540-71285-5},
	url = {http://link.springer.com/10.1007/978-3-540-71285-5},
	series = {Lecture Notes in Mathematics},
	shorttitle = {Differential Equations Driven by Rough Paths},
	publisher = {Springer Berlin Heidelberg},
	author = {Lyons, Terry J. and Caruana, Michael and Levy, Thierry},
	editorb = {Cachan, J.-M. Morel and Groningen, F. Takens and Paris, B. Teissier},
	editorbtype = {redactor},
	urldate = {2021-09-27},
	date = {2007},
	langid = {english},
	doi = {10.1007/978-3-540-71285-5},
	file = {Lyons et al. - 2007 - Differential Equations Driven by Rough Paths Écol.pdf:/Users/Dodo/Zotero/storage/UKUDPNUH/Lyons et al. - 2007 - Differential Equations Driven by Rough Paths Écol.pdf:application/pdf}
}

@article{reizenstein_iisignature_2016,
	title = {iisignature (version 0.24)},
	abstract = {The iisignature Python package is designed to provide an easy-to-use reasonably eﬃcient implementation of iterated-integral signatures and log-signatures of piecewise linear paths. Some motivation as to the usefulness of these things in machine learning may be found in [3]. This software is described in the paper [{iisigPaper}], which users may wish to cite.},
	pages = {9},
	author = {Reizenstein, Jeremy and Graham, Ben},
	date = {2016},
	langid = {english},
	file = {Reizenstein und Graham - iisignature (version 0.24).pdf:/Users/Dodo/Zotero/storage/DIMS69BE/Reizenstein und Graham - iisignature (version 0.24).pdf:application/pdf}
}

@book{peskir_optimal_2006,
	location = {Basel ; Boston},
	title = {Optimal stopping and free-boundary problems},
	isbn = {978-3-7643-2419-3 978-3-7643-7390-0},
	series = {Lectures in mathematics {ETH} Zürich},
	pagetotal = {500},
	publisher = {Birkhaeuser Verlag},
	author = {Peskir, G. and Shiriaev, A. N.},
	date = {2006},
	langid = {english},
	keywords = {Boundary value problems, Economics, Mathematical, Nonlinear integral equations, Optimal stopping (Mathematical statistics)},
	file = {Peskir und Shiri︠a︡ev - 2006 - Optimal stopping and free-boundary problems.pdf:/Users/Dodo/Zotero/storage/HFQ52NMS/Peskir und Shiri︠a︡ev - 2006 - Optimal stopping and free-boundary problems.pdf:application/pdf}
}





@book{barola2014monte,
  title={Monte Carlo Methods for American Option Pricing},
  author={Barola, Alberto},
  year={2014},
  publisher={LAP LAMBERT Academic Publishing}
}

@incollection{schweizer2002bermudan,
  title={On bermudan options},
  author={Schweizer, Martin},
  booktitle={Advances in finance and stochastics},
  pages={257--270},
  year={2002},
  publisher={Springer}
}

@book{grimmett2020probability,
  title={Probability and random processes},
  author={Grimmett, Geoffrey and Stirzaker, David},
  year={2020},
  publisher={Oxford university press}
}

@phdthesis{fawcett2002problems,
  title={Problems in stochastic analysis: Connections between rough paths and non-commutative harmonic analysis},
  author={Fawcett, Thomas},
  year={2002},
  school={University of Oxford}
}

@article{garcia2003convergence,
  title={Convergence and biases of Monte Carlo estimates of American option prices using a parametric exercise rule},
  author={Garc{\i}a, Diego},
  journal={Journal of Economic Dynamics and Control},
  volume={27},
  number={10},
  pages={1855--1879},
  year={2003},
  publisher={Elsevier}
}

@article{boyle2003improved,
  title={An improved simulation method for pricing high-dimensional American derivatives},
  author={Boyle, Phelim P and Kolkiewicz, Adam W and Tan, Ken Seng},
  journal={Mathematics and Computers in Simulation},
  volume={62},
  number={3-6},
  pages={315--322},
  year={2003},
  publisher={Elsevier}
}

@article{tieleman2012lecture,
  title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen and Hinton, Geoffrey and others},
  journal={COURSERA: Neural networks for machine learning},
  volume={4},
  number={2},
  pages={26--31},
  year={2012}
}

@incollection{kulikov2016stopping,
  title={Stopping times for fractional Brownian motion},
  author={Kulikov, Alexander V and Gusyatnikov, Pavel P},
  booktitle={Computational Management Science},
  pages={195--200},
  year={2016},
  publisher={Springer}
}

@article{eilenberg1953groups,
  title={On the groups H ($\pi$, n), I},
  author={Eilenberg, Samuel and Lane, Saunders Mac},
  journal={Annals of Mathematics},
  pages={55--106},
  year={1953},
  publisher={JSTOR}
}

@inproceedings{deng2013recent,
  title={Recent advances in deep learning for speech research at Microsoft},
  author={Deng, Li and Li, Jinyu and Huang, Jui-Ting and Yao, Kaisheng and Yu, Dong and Seide, Frank and Seltzer, Michael and Zweig, Geoff and He, Xiaodong and Williams, Jason and others},
  booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={8604--8608},
  year={2013},
  organization={IEEE}
}


